# .github/workflows/ci-cd-pipeline.yml

name: DevOps Meme/Quote Generator CI/CD Pipeline

on:
  # Triggers the workflow on push events to the master branch (for apply job)
  push:
    branches: [ "master" ]
  # Triggers the workflow on pull request events but only for the master branch
  pull_request:
    branches: [ "master" ]
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  # --- Job: Build and Test ---
  build-test:
    name: 'Build & Test Docker Image'
    runs-on: ubuntu-latest

    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE
      - uses: actions/checkout@v4

      # Example step: Set up Python (if needed for local tests)
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # Example step: Install dependencies (if running local tests)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Check if requirements.txt exists and install dependencies
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # --- Docker Steps ---
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Docker Hub (or ECR)
        # Use secrets to store your Docker Hub/ECR credentials
        # This example assumes Docker Hub. Adjust for ECR if needed.
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }} # Set this secret in GitHub
          password: ${{ secrets.DOCKERHUB_TOKEN }}    # Set this secret in GitHub

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true # Push the image
          # Tag the image with the commit SHA for uniqueness
          tags: samisondocker/devops-meme-quote-generator:${{ github.sha }} # <--- YOUR USERNAME

  # --- Job: Terraform Plan ---
  terraform-plan:
    name: 'Terraform Plan'
    # This job runs only on pull requests
    if: github.event_name == 'pull_request'
    # It needs to run on the same runner type
    runs-on: ubuntu-latest
    # It should only run after the build-test job succeeds
    needs: build-test

    # Grant necessary permissions for commenting on PRs
    permissions:
      contents: read  # Default for GITHUB_TOKEN, needed to checkout code
      pull-requests: write # Explicitly grant write permission to PRs for commenting

    # Environment variables specific to this job
    env:
      TF_VAR_ssh_key_name: ${{ secrets.TF_SSH_KEY_NAME }} # Pass SSH key name as a TF variable

    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE
      - name: Checkout
        uses: actions/checkout@v4

      # Set up Terraform CLI
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      # Configure AWS credentials (needed for Terraform to interact with AWS)
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1 # Use the same region as your Terraform config

      # Navigate to the terraform directory and run Terraform commands
      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform

      # Terraform Validate
      - name: Terraform Validate
        run: terraform validate
        working-directory: ./terraform

      # Terraform Plan
      - name: Terraform Plan
        id: plan # Give this step an ID so we can reference its output later
        run: |
          # Run plan and capture output
          PLAN_OUTPUT=$(terraform plan -no-color 2>&1)
          # Save to GITHUB_ENV
          echo "TF_PLAN<<EOF" >> $GITHUB_ENV
          echo "$PLAN_OUTPUT" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          # Also save to file for debugging/artifacts
          echo "$PLAN_OUTPUT" > tfplan.txt
        working-directory: ./terraform
        # Continue on error to allow posting the plan even if it fails (e.g., syntax error)
        continue-on-error: true

      # Post the plan as a comment on the PR
      - name: Comment Terraform Plan on PR
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request' # Only run on PRs
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const planOutput = process.env.TF_PLAN || "No plan output available.";
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number, # PR is an issue in GitHub API
              body: `## Terraform Plan Output\n\`\`\`hcl\n${planOutput}\n\`\`\``
            });

  # --- Job: Terraform Apply ---
  terraform-apply:
    name: 'Terraform Apply (Manual Approval Required)'
    # This job runs on push to master (e.g., after PR merge) or manual dispatch
    # CORRECTED CONDITION: Added parentheses for clarity and correctness
    if: (github.ref == 'refs/heads/master' && github.event_name == 'push') || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    # Depends on the build-test job
    needs: [build-test]

    # --- Approval Gate using Environment ---
    # YES, this references the 'production' environment you created.
    environment:
      name: production # Name of the environment (create this in GitHub repo settings)
      url: ${{ steps.get_ip.outputs.public_ip_url }} # Optional: URL for the deployed app

    env:
      TF_VAR_ssh_key_name: ${{ secrets.TF_SSH_KEY_NAME }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      # Navigate to the terraform directory and initialize
      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform

      # Terraform Validate
      - name: Terraform Validate
        run: terraform validate
        working-directory: ./terraform

      # Terraform Apply
      - name: Terraform Apply
        run: terraform apply -auto-approve
        working-directory: ./terraform

      # Capture the EC2 IP for later use/validation
      - name: Get EC2 Public IP
        id: get_ip # Give this step an ID to reference its output
        run: |
          # Use terraform output to get the IP
          export EC2_IP=$(terraform output -raw ec2_instance_public_ip)
          echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
          # Create a URL output
          echo "public_ip_url=http://$EC2_IP:5000" >> $GITHUB_OUTPUT
        working-directory: ./terraform

  # --- Job: Ansible Configure Instance ---
  ansible-configure:
    name: 'Ansible Configure Instance (Manual Approval Required)'
    # Run after Terraform apply, on master push or manual dispatch
    if: (github.ref == 'refs/heads/master' && github.event_name == 'push') || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    needs: [terraform-apply] # Must wait for infrastructure

    # --- Approval Gate using Environment ---
    environment:
      name: configure-production # Create this environment in GitHub settings if needed
      # url: ${{ steps.get_ip.outputs.public_ip_url }} # Optional, if you want a direct link

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # Setup Python for Ansible
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      # Install Ansible
      - name: Install Ansible
        run: |
          pip install --upgrade pip
          pip install ansible

      # Configure AWS credentials (might be needed if using dynamic inventory)
      - name: Configure AWS Credentials (for Ansible EC2 inventory if needed)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1 # Use the same region as your Terraform config

      # --- KEY PART: Setup SSH for Ansible ---
      # Store the private SSH key in GitHub Secrets (e.g., TF_SSH_PRIVATE_KEY)
      # It's crucial this secret contains the *private* key content, including
      # the "-----BEGIN OPENSSH PRIVATE KEY-----" and "-----END OPENSSH PRIVATE KEY-----" lines.
      - name: Setup SSH Key for Ansible
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.TF_SSH_PRIVATE_KEY }} # Add this secret!

      # Get Terraform Outputs (IP, potentially Image Tag if not using latest)
      - name: Get Terraform Outputs
        id: get_outputs
        run: |
          cd terraform
          # Ensure Terraform is initialized to read state from S3 backend
          terraform init || echo "Terraform init failed, but continuing..."
          export EC2_IP=$(terraform output -raw ec2_instance_public_ip)
          if [ -z "$EC2_IP" ]; then
            echo "ERROR: Could not retrieve EC2 Public IP from Terraform outputs."
            exit 1
          fi
          echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
          # Use the commit SHA as the image tag, matching the build-test job
          # IMPORTANT: Replace 'samisondocker' with your actual Docker Hub username!
          export IMAGE_TAG="samisondocker/devops-meme-quote-generator:${{ github.sha }}"
          echo "IMAGE_TAG=$IMAGE_TAG" >> $GITHUB_ENV
        # Ensure Terraform is initialized to read state
        working-directory: ./terraform

      # Create a simple Ansible inventory (or use ec2.py dynamic inventory)
      - name: Create Ansible Inventory
        run: |
          mkdir -p ansible/inventory
          cat > ansible/inventory/hosts <<EOF
          [web_app_hosts]
          web_app ansible_host=${{ env.EC2_IP }} ansible_user=ec2-user ansible_ssh_common_args='-o StrictHostKeyChecking=no'
          EOF

      # Run the Ansible Playbook
      - name: Run Ansible Playbook
        run: |
          cd ansible
          ansible-playbook -i inventory/hosts configure-web-app.yml \
            -e "docker_image_tag=${{ env.IMAGE_TAG }} ec2_public_ip=${{ env.EC2_IP }}"
